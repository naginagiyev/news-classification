{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbf6d91",
   "metadata": {},
   "source": [
    "_Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5012b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61429eaa",
   "metadata": {},
   "source": [
    "_Model Setup_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    def __init__(self, data_path):\n",
    "        # əgər varsa train gpu-da olacaq, yoxdursa cpu ilə davam edəcək\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # datanı yükləyib bölən funksiyanı çağır\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.load_data(data_path)\n",
    "        # tokenizerı initialize et \n",
    "        print(f\"Loaded data with {len(self.train_texts)} train, {len(self.eval_texts)} eval, {len(self.test_texts)} test samples\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\", max_length=512)\n",
    "        print(\"Tokenizer loaded\")\n",
    "        self.setup_model()\n",
    "        print(\"Model loaded and moved to device\")\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        # datanı yüklə\n",
    "        df = pd.read_parquet(path)\n",
    "\n",
    "        # datanı qarışdır\n",
    "        df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # label2id və id2label yarat, model üçün kateqoriyaları rəqəmlərə çevirir\n",
    "        labels = df['category'].unique().tolist()\n",
    "        labels = [s.strip() for s in labels]\n",
    "        num_labels = len(labels)\n",
    "        id2label = {id: label for id, label in enumerate(labels)}\n",
    "        label2id = {label: id for id, label in enumerate(labels)}\n",
    "        df[\"labels\"] = df['category'].map(lambda x: label2id[x.strip()])\n",
    "\n",
    "        # datanı train (70%), test (20%), validationa (10%) böl\n",
    "        size = len(df)\n",
    "        train_end = int(size * 0.7)\n",
    "        test_end = int(size * 0.9)\n",
    "        self.train_texts = list(df['text'][:train_end])\n",
    "        self.test_texts = list(df['text'][train_end:test_end])\n",
    "        self.eval_texts = list(df['text'][test_end:])\n",
    "        self.train_labels = list(df['labels'][:train_end])\n",
    "        self.test_labels = list(df['labels'][train_end:test_end])\n",
    "        self.eval_labels = list(df['labels'][test_end:])\n",
    "        self.num_labels = num_labels\n",
    "        self.id2label = id2label\n",
    "        self.label2id = label2id\n",
    "    \n",
    "    # modeli yarat və gpu-ya göndər (yoxdursa cpu)\n",
    "    def setup_model(self):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"FacebookAI/xlm-roberta-base\",\n",
    "            num_labels=self.num_labels,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    # datanı encode et \n",
    "    def encode_data(self, texts):\n",
    "        print(f\"Encoding {len(texts)} texts...\")\n",
    "        return self.tokenizer(texts, truncation=True, padding=True)\n",
    "\n",
    "    # encode olunmuş textləri transformer modellərin başa düşdüyü dataset formasında qaytar\n",
    "    def create_data_loader(self, encodings, labels):\n",
    "        class CustomDataset(Dataset):\n",
    "            def __init__(self, encodings, labels):\n",
    "                self.encodings = encodings\n",
    "                self.labels = labels\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "                item['labels'] = torch.tensor(self.labels[idx])\n",
    "                return item\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.labels)\n",
    "        print(f\"Creating dataset with {len(labels)} samples\")\n",
    "        return CustomDataset(encodings, labels)\n",
    "    \n",
    "    # metrikləri hesablamaq üçün funksiya\n",
    "    def compute_metrics(self, pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'Accuracy': acc,\n",
    "            'Weighted F1': f1,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall\n",
    "        }\n",
    "\n",
    "    # training və evaluation argumentlərini initialize et və trainə başla\n",
    "    def train_and_evaluate(self):\n",
    "        train_encodings = self.encode_data(self.train_texts)\n",
    "        eval_encodings = self.encode_data(self.eval_texts)\n",
    "        test_encodings = self.encode_data(self.test_texts)\n",
    "        train_dataset = self.create_data_loader(train_encodings, self.train_labels)\n",
    "        eval_dataset = self.create_data_loader(eval_encodings, self.eval_labels)\n",
    "        test_dataset = self.create_data_loader(test_encodings, self.test_labels)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            report_to=\"none\",\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            eval_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            load_best_model_at_end=True\n",
    "        )\n",
    "        print(\"Starting training...\")\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            compute_metrics=self.compute_metrics\n",
    "        )\n",
    "        trainer.train()\n",
    "        print(\"Training finished. Evaluating on test set...\")\n",
    "        results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "        print(\"Evaluation done.\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traini başlat\n",
    "classifier = TextClassifier(\"./data/data.parquet\")\n",
    "results = classifier.train_and_evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95228668",
   "metadata": {},
   "source": [
    "_Confusion Matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = classifier.encode_data(classifier.test_texts)\n",
    "test_dataset = classifier.create_data_loader(test_encodings, classifier.test_labels)\n",
    "\n",
    "trainer = Trainer(model=classifier.model, args=TrainingArguments(output_dir='./results', report_to=\"none\"))\n",
    "predictions_output = trainer.predict(test_dataset)\n",
    "preds = predictions_output.predictions.argmax(-1)\n",
    "labels = predictions_output.label_ids\n",
    "\n",
    "cm = confusion_matrix(labels, preds, normalize='true')\n",
    "labels_names = list(classifier.id2label.values())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_names)\n",
    "disp.plot(cmap='YlOrRd', ax=ax,  xticks_rotation=45,  values_format=\".2f\")\n",
    "plt.title(\"Normalized Confusion Matrix (%)\", fontsize=16)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c666f",
   "metadata": {},
   "source": [
    "_Save Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571888d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/content/model\"\n",
    "classifier.model.save_pretrained(save_path)\n",
    "classifier.tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa28d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asantask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
