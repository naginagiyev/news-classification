{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053a3635",
   "metadata": {},
   "source": [
    "_Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from azstemmer import AzStemmer\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from functions import add_spacing, remove_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tqdm.pandas()\n",
    "stemmer = AzStemmer(keyboard=\"az\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21eb5d",
   "metadata": {},
   "source": [
    "_Load Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bd413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_parquet(\"./data/data.parquet\")\n",
    "df.dropna(subset=['title', 'text', 'category'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa054375",
   "metadata": {},
   "source": [
    "_Stem Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8139a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem data using azstemmer (https://pypi.org/project/azstemmer/)\n",
    "# NOTE: Azstemmer is a library created by me to reduce words into their roots \n",
    "\n",
    "print(\"Stemming...\")\n",
    "df['title'] = df['title'].progress_apply(stemmer.stem)\n",
    "df['text'] = df['text'].progress_apply(stemmer.stem)\n",
    "\n",
    "# adding spacings between symbols, numbers and words\n",
    "print(\"Adding spacings...\")\n",
    "df['title'] = df['title'].progress_apply(add_spacing)\n",
    "df['text'] = df['text'].progress_apply(add_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46982559",
   "metadata": {},
   "source": [
    "_Remove Stopwords_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words \n",
    "# NOTE: stop wordləri silməsək biraz daha yaxşı nəticə verir amma göstərmə məqsədi ilə sildim\n",
    "print(\"Removing stop words...\")\n",
    "df['title'] = df['title'].progress_apply(remove_stopwords)\n",
    "df['text'] = df['text'].progress_apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c7374",
   "metadata": {},
   "source": [
    "_Split Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cdfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "title = df['title']\n",
    "text = df['text']\n",
    "y = df['category']\n",
    "\n",
    "title_train, title_test, text_train, text_test, y_train, y_test = train_test_split(title, text, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f35bdf",
   "metadata": {},
   "source": [
    "_Vectorize Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a81d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize texts using count vectorizer\n",
    "title_vectorizer = CountVectorizer(max_features=7500, min_df=2, max_df=0.95)\n",
    "text_vectorizer = CountVectorizer(max_features=15000, min_df=2, max_df=0.95)\n",
    "\n",
    "title_train_vec = title_vectorizer.fit_transform(title_train)\n",
    "text_train_vec = text_vectorizer.fit_transform(text_train)\n",
    "X_train_vec = hstack([title_train_vec, text_train_vec])\n",
    "\n",
    "title_test_vec = title_vectorizer.transform(title_test)\n",
    "text_test_vec = text_vectorizer.transform(text_test)\n",
    "X_test_vec = hstack([title_test_vec, text_test_vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed15995",
   "metadata": {},
   "source": [
    "_Set Balanced Class Weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize class weights balanced in order to prevent overfitting\n",
    "classes = y.unique()\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "weights = dict(zip(classes, class_weights))\n",
    "sample_weights = y_train.map(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c6226",
   "metadata": {},
   "source": [
    "_Training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fit model\n",
    "model = CatBoostClassifier(iterations=100, learning_rate=0.13, early_stopping_rounds=30, random_state=42)\n",
    "model.fit(X_train_vec, y_train, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f99ae4",
   "metadata": {},
   "source": [
    "_Evaluation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dab095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model's performance on train and test data\n",
    "y_pred_train = model.predict(X_train_vec)\n",
    "train_score = f1_score(y_train, y_pred_train, average='weighted')\n",
    "\n",
    "y_pred_test = model.predict(X_test_vec)\n",
    "test_score = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"Train Weighted F1 Score:\", train_score)\n",
    "print(\"Test Weighted F1 Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=model.classes_)\n",
    "\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "cm_percent = np.nan_to_num(cm_percent)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(cm_percent, annot=True, fmt=\".2f\", cmap=\"YlOrRd\",\n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Percentages)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910be48",
   "metadata": {},
   "source": [
    "_Save model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e889a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./models/catboost\", exist_ok=True)\n",
    "with open(\"./models/catboost/title_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(title_vectorizer, f)\n",
    "\n",
    "with open(\"./models/catboost/text_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(text_vectorizer, f)\n",
    "\n",
    "model.save_model(\"./models/catboost/model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ac243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asantask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
