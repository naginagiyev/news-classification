import torch
import pickle
import numpy as np
import streamlit as st
from azstemmer import AzStemmer
from scipy.sparse import hstack
import torch.nn.functional as F
from catboost import CatBoostClassifier
from functions import clean_text, add_spacing, remove_stopwords
from transformers import AutoTokenizer, AutoModelForSequenceClassification

torch.classes.__path__ = []

# azstemmer kitabxanasÄ±ndan bir obyekt yarat
stemmer = AzStemmer(keyboard="az")

# catboost vectorizerlerini yÃ¼klÉ™
with open('./models/catboost/title_vectorizer.pkl', 'rb') as f:
    title_vectorizer = pickle.load(f)

with open('./models/catboost/text_vectorizer.pkl', 'rb') as f:
    text_vectorizer = pickle.load(f)

# catboost modelini yÃ¼klÉ™
catboost_model = CatBoostClassifier()
catboost_model.load_model('./models/catboost/model.cbm')

# xlm-roberta modeli Ã¼Ã§Ã¼n id2label
label_map = {0: 'tÉ™hsil', 1: 'ÅŸou-biznes', 2: 'yazarlar', 3: 'siyasÉ™t', 4: 'region', 5: 'media',
             6: 'hadisÉ™', 7: 'iÌ‡dman', 8: 'texnologiya', 9: 'yaÅŸam', 10: 'mÉ™dÉ™niyyÉ™t', 11: 'sosial',
             12: 'astrologiya', 13: 'mÃ¼sahibÉ™', 14: 'iÌ‡qtisadiyyat', 15: 'other'}

# xlm-roberta-base modelini vÉ™ vectorizerini yÃ¼klÉ™ 
model_path = "./models/xlm-roberta"
tokenizer = AutoTokenizer.from_pretrained(model_path)
xlm_model = AutoModelForSequenceClassification.from_pretrained(model_path)

# istifadÉ™Ã§i interfeysi
st.title("ğŸ“° XÉ™bÉ™r SiniflÉ™ndirmÉ™")

model_choice = st.radio(
    "ğŸ¤– Model seÃ§in",
    ["CatBoost", "XLM-RoBERTa"],
    horizontal=True
)

title_input = st.text_area("ğŸ”– XÉ™bÉ™r baÅŸlÄ±ÄŸÄ±", height=75)
text_input = st.text_area("ğŸ§¾ XÉ™bÉ™r mÉ™tni", height=150)

# istifadÉ™Ã§iyÉ™ modeli seÃ§mÉ™k imkanÄ± verilir vÉ™ seÃ§ilÉ™n modelÉ™ uyÄŸun prediction qaytarÄ±lÄ±r
if st.button("TÉ™xmin et ğŸ¤”"):
    if not title_input.strip() or not text_input.strip():
        st.warning("ZÉ™hmÉ™t olmasa xÉ™bÉ™r baÅŸlÄ±ÄŸÄ±nÄ± vÉ™ mÉ™tnini daxil edin")
    elif len(title_input.strip().split()) < 3:
        st.warning("XÉ™bÉ™r baÅŸlÄ±ÄŸÄ± É™n az 3 sÃ¶zdÉ™n ibarÉ™t olmalÄ±dÄ±r!")
    elif len(text_input.strip().split()) < 20:
        st.warning("XÉ™bÉ™r mÉ™tni É™n az 20 sÃ¶zdÉ™n ibarÉ™t olmalÄ±dÄ±r!")
    else:
        if model_choice == "CatBoost":
            preprocessed_title = remove_stopwords(add_spacing(stemmer.stem(clean_text(title_input))))
            preprocessed_text = remove_stopwords(add_spacing(stemmer.stem(clean_text(text_input))))

            title_vec = title_vectorizer.transform([preprocessed_title])
            text_vec = text_vectorizer.transform([preprocessed_text])
            combined_vec = hstack([title_vec, text_vec])

            pred_class = catboost_model.predict(combined_vec)[0]
            pred_proba = catboost_model.predict_proba(combined_vec)[0]
            confidence = np.max(pred_proba) * 100

            st.success(f"**TÉ™xmin olunan kateqoriya:** {str(pred_class[0]).capitalize()}")
            st.success(f"{confidence:.2f}% É™minÉ™m ğŸ˜Š")
        
        else: 
            combined_text = f"{title_input} - {text_input}"
            preprocessed_text = clean_text(combined_text)
            
            xlm_model.eval()
            
            device = torch.device('cpu')
            xlm_model = xlm_model.to(device)
            
            inputs = tokenizer(preprocessed_text, return_tensors="pt", truncation=True, padding=True)
            inputs = {k: v.to(device) for k, v in inputs.items()}

            with torch.no_grad():
                outputs = xlm_model(**inputs)
                probs = F.softmax(outputs.logits, dim=1)
            
            pred_id = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_id].item() * 100
            pred_label = label_map[pred_id]
            
            st.success(f"**TÉ™xmin olunan kateqoriya:** {pred_label.capitalize()}")
            st.success(f"{confidence:.2f}% É™minÉ™m ğŸ˜Š")