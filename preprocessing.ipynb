{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd5a31",
   "metadata": {},
   "source": [
    "_Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a237cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functions import clean_text\n",
    "from datasets import load_dataset\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862d60e",
   "metadata": {},
   "source": [
    "_Load Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a37a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"LocalDoc/news_azerbaijan_2\")\n",
    "\n",
    "# huggingface datasetini dataframe-yə çevirdik\n",
    "df = ds[\"train\"].to_pandas()\n",
    "\n",
    "# bütün hərfləri kiçik etdik\n",
    "df = df.apply(lambda col: col.str.lower() if col.dtype == 'object' else col)\n",
    "\n",
    "# lazımsız sütunları, duplikatları, nulları sildik\n",
    "df.drop(columns=[\"id\", \"date\"], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55324e7",
   "metadata": {},
   "source": [
    "_Clean Dataset from Unusual Symbols_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71abaa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 752458/752458 [00:07<00:00, 100617.21it/s]\n",
      "100%|██████████| 752458/752458 [01:29<00:00, 8395.25it/s] \n"
     ]
    }
   ],
   "source": [
    "# textləri təmizlədik - sadəcə hərflər, rəqəmlər və bir neçə əsas durğu işarəsini saxladıq\n",
    "for col in ['title', 'text']:\n",
    "    df[col] = df[col].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0c0e5",
   "metadata": {},
   "source": [
    "_Drop Rows with Outlier Word Counts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dae19ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "Title - Min: 1\n",
      "Title - Max: 1309\n",
      "Title - Mean: 7.328385105879664\n",
      "Title - Median: 7.0\n",
      "\n",
      "Text - Min: 2\n",
      "Text - Max: 73078\n",
      "Text - Mean: 233.79241366295528\n",
      "Text - Median: 118.0\n",
      "ROW COUNT BEFORE: 752458\n",
      "\n",
      "AFTER\n",
      "Title - Min: 3\n",
      "Title - Max: 15\n",
      "Title - Mean: 7.2987246800049705\n",
      "Title - Median: 7.0\n",
      "\n",
      "Text - Min: 20\n",
      "Text - Max: 500\n",
      "Text - Mean: 141.78787280974277\n",
      "Text - Median: 102.0\n",
      "ROW COUNT AFTER: 643760\n"
     ]
    }
   ],
   "source": [
    "# Çox uzun və çox qısa olan textləri sildik\n",
    "# XLM modeli maksimum 512 token qəbul edir. Bundan uzun olan textləri özü truncate edir.\n",
    "# buna görə də çox uzun textlər saxlamağa ehtiyac yoxdur. Çünki model onsuz da onları kəsəcək və bu da contextin yarımçıq qalmasına səbəb olacaq.\n",
    "# içərisində 1-2 söz olan textləri də saxlamağa ehtiyac yoxdur, çünki onlar kontent cəhətdən qıtdırlar.\n",
    "\n",
    "df['title_word_count'] = df['title'].str.count(r'\\S+')\n",
    "df['text_word_count'] = df['text'].str.count(r'\\S+')\n",
    "\n",
    "print(\"BEFORE\")\n",
    "print(\"Title - Min:\", df['title_word_count'].min())\n",
    "print(\"Title - Max:\", df['title_word_count'].max())\n",
    "print(\"Title - Mean:\", df['title_word_count'].mean())\n",
    "print(\"Title - Median:\", df['title_word_count'].median())\n",
    "print()\n",
    "print(\"Text - Min:\", df['text_word_count'].min())\n",
    "print(\"Text - Max:\", df['text_word_count'].max())\n",
    "print(\"Text - Mean:\", df['text_word_count'].mean())\n",
    "print(\"Text - Median:\", df['text_word_count'].median())\n",
    "print(\"ROW COUNT BEFORE:\", len(df))\n",
    "\n",
    "df = df[\n",
    "    (df['title_word_count'].between(3, 15)) &\n",
    "    (df['text_word_count'].between(20, 500))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "df['title_word_count'] = df['title'].str.count(r'\\S+')\n",
    "df['text_word_count'] = df['text'].str.count(r'\\S+')\n",
    "\n",
    "print(\"\\nAFTER\")\n",
    "print(\"Title - Min:\", df['title_word_count'].min())\n",
    "print(\"Title - Max:\", df['title_word_count'].max())\n",
    "print(\"Title - Mean:\", df['title_word_count'].mean())\n",
    "print(\"Title - Median:\", df['title_word_count'].median())\n",
    "print()\n",
    "print(\"Text - Min:\", df['text_word_count'].min())\n",
    "print(\"Text - Max:\", df['text_word_count'].max())\n",
    "print(\"Text - Mean:\", df['text_word_count'].mean())\n",
    "print(\"Text - Median:\", df['text_word_count'].median())\n",
    "print(\"ROW COUNT AFTER:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734f9d3",
   "metadata": {},
   "source": [
    "_Group and Drop Classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209b8ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son xəbər:  141529\n",
      "dünya:  136222\n",
      "ölkə:  100151\n",
      "gündəm:  40672\n",
      "kriminal:  34599\n",
      "siyasət:  33323\n",
      "i̇dman:  32472\n",
      "hadisə:  31705\n",
      "i̇qtisadiyyat:  19361\n",
      "şou-biznes:  10405\n",
      "region:  9472\n",
      "maraqlı:  8983\n",
      "yazarlar:  7319\n",
      "media:  7188\n",
      "mədəniyyət:  4742\n",
      "təhsil:  4128\n",
      "sosial:  3605\n",
      "yaşam:  3479\n",
      "səhiyyə:  3044\n",
      "reportaj:  1843\n",
      "astrologiya:  1802\n",
      "texnologiya:  1780\n",
      "qarabağ xəbərləri:  1582\n",
      "qalmaqal:  843\n",
      "müsahibə:  538\n",
      "ki̇vdf layihələri:  525\n",
      "mənəviyyat:  464\n",
      "güney hadisələri:  369\n",
      "xəbər xətti:  301\n",
      "video:  251\n",
      "formula #1:  234\n",
      "proje:  146\n",
      "foto fakt:  125\n",
      "analitika:  100\n",
      "i̇slamiada:  98\n",
      "yaxın tarix:  88\n",
      "rəsmi:  59\n",
      "mətbuat bugün:  47\n",
      "oxucu poçtu:  39\n",
      "hərbi xəbərlər:  33\n",
      "dünyanın bu üzü:  28\n",
      "seçki 2024:  24\n",
      "vaxt axarı:  18\n",
      "fotosessiya:  9\n",
      "sözsüz:  8\n",
      "bizim qonaq:  5\n",
      "yavru vatanın səsi:  2\n"
     ]
    }
   ],
   "source": [
    "# göründüyü kimi datada həddindən artıq çox kateqoriya var və bir xeyli imbalance şəkildə\n",
    "for category, count in df['category'].value_counts().to_dict().items():\n",
    "    print(f\"{category}:  {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deeaa3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QEYD: aşağıda etdiyim bütün atmalar və ya birləşdirmələr öz intuisiyama görə olmayıb.\n",
    "# modelin bir dəfə train olunub nəticələrinə baxandan və datanı daha dərin analiz edəndən sonra bu qərara gəldim.\n",
    "# sadəcə olaraq qarışıqlığın qarşısını almaq üçün ayrıca notebook-da göstərməmişəm\n",
    "\n",
    "# aşağıda atılan sütunların atılma səbəbləri:\n",
    "# son xəbər, ölkə, gündəm - bunlar ayrıca bir kateqoriya deyil. Müxtəlif kateqoriyalardan olan xəbərləri özlərində saxlayırlar.\n",
    "# məsələn. əgər bir xəbər siyasət və ya iqtisadiyyat olsun fərq etmir, yeni çıxıbsa, o həm də son xəbər kateqoriyasında olacaq.\n",
    "# və bu zaman da model onu digər siniflərlə çox qarışdıracaq\n",
    "# sübut kimi xlm-roberta modelinin aşağıdakı dəyişikliləri etməmişdən əvvəl train olunmuş halının classification reportunu /results folderinə əlavə etmişəm (result1.png)\n",
    "# ki̇vdf layihələri - hansısa bir zaman dilimində olub və hazırda bu kimi xəbərlər yoxdur deyə atılıb\n",
    "\n",
    "drop_cats = ['son xəbər', 'ölkə', 'gündəm', 'ki̇vdf layihələri', 'dünya']\n",
    "df = df[~df['category'].isin(drop_cats)]\n",
    "\n",
    "# bu siniflər demək olar ki bir-biri ilə eyni tip xəbərlərə malikdir\n",
    "# bu səbəbə birləşdirilmişdir\n",
    "merge_map = {\n",
    "    'yaşam': ['yaşam', 'maraqlı', 'səhiyyə'],\n",
    "    'siyasət': ['qarabağ xəbərləri', 'siyasət', 'seçki 2024'],\n",
    "    'i̇dman': ['i̇dman', 'formula #1', 'i̇slamiada'],\n",
    "    'region': ['region', 'güney hadisələri'],\n",
    "    'şou-biznes': ['şou-biznes', 'qalmaqal'],\n",
    "    'müsahibə': ['müsahibə', 'reportaj'],\n",
    "    'hadisə': ['hadisə', 'kriminal']\n",
    "}\n",
    "\n",
    "for new_cat, old_cats in merge_map.items():\n",
    "    df['category'] = df['category'].replace(old_cats, new_cat)\n",
    "\n",
    "# sayı 500-dən az olan dataları class sayını azaltmaq üçün other adı altında yeni bir classda birləşdirdim\n",
    "category_counts = df['category'].value_counts()\n",
    "rare_cats = category_counts[category_counts < 500].index\n",
    "df['category'] = df['category'].apply(lambda x: 'other' if x in rare_cats else x)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ac708",
   "metadata": {},
   "source": [
    "_Undersampling_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14de5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datanın sayı çox olduğundan həm train gec olur, həm də komputerimi yandıra bilər :).\n",
    "# datanın sayını azaltmaqla bağlı tapşırıqda limit də olmadığı üçün, undersampling edərək biraz imbalanclığı aradan qaldırmağa çalışdım \n",
    "df = (df.groupby('category').apply(lambda x: x.sample(n=6000, random_state=42) if len(x) > 6000 else x).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081c1cd",
   "metadata": {},
   "source": [
    "_Combined Colum for XLM-ROBERTA Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input'] = df['title'] + ' - ' + df['text']\n",
    "df.drop(columns=[\"title_word_count\", \"text_word_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c659c5",
   "metadata": {},
   "source": [
    "_Save Preprocessed Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be89b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"./data/data.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e37479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asantask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
